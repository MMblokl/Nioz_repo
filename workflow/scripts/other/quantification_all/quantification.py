#Complete script that makes a bunch of quantification estimates using different methods
import os
import glob
import numpy
import ast
import sys

#This script generates estimated abundances using all tested method from the report.
# These methods are numbered, which specific method is used can be found here:

##############
#ARGUMENTS:
sampleid = sys.argv[1] #The id of the current sample
bins_dir = sys.argv[2] #The path to the directory with all final bins to be quantified.
unbinned_contigs = sys.argv[3] #The file location of the unbinned contigs file generated by find_residuals.py
readmapping = sys.argv[4] #The file showing the amount of unique mapping reads for each contig in the sample generated by get_read_mapping.sh.
contig_depthfile = sys.argv[5] #The file location of the contig depth file generated by the collect_contig_depth.R script.
salmon_quant = sys.argv[6] #The quant.sf file generated by using salmon quant generated by the salmon_quant.sh script.
genomesizes_file = sys.argv[7] #The genomesize tab file generated by calc_genomesize.R
outputfile = sys.argv[8] #The name and location for the output quant tab.
##############


#LOTS OF INPUTS NEEDED



####################
#METHOD NUMBERING AND EXPLINATION:
#1: Total number of unique reads aligning to all contigs in a bin, divided by
# the total number of reads in the sample.
#
# binreads / total reads


#2: Sum of kmer coverages in all contigs in a bin, divided by the total sum of
# all kmer coverages over the entire sample.
# This coverage is a value taken from the contig header, generated by metaSPAdes.
#
# bincoverage / total coverage


#3: The average read depth of all contigs in a bin, divided by the total sum of
# these averages over the entire sample.
#
# Average contigdepth entire bin / total sum average bin contigdepth


#4: The median read depth of all contigs in a bin, divided by the total sum of
# these averages over the entire sample.
#
# Median contigdepth entire bin / total sum median contigdepth bin


#5: Amount of reads mapping to all contigs in a bin, multiplied by the average
# read depth of all contigs in said bin.
#This is then divided by the total sum of these values over the entire sample
#
# (Total reads in bin * average contigdepth entire bin) / sum average bindepth adjusted reads


#6: Amount of reads mapped to all contigs in a bin, multiplied by the median read
# depth of all contigs in said bin.
# This is then divided by the total sum of these values over the entire sample
#
# (Total reads in bin * median contigdepth entire bin) / sum median bindepth adjusted reads


#7: The amount of reads mapping to a contig is divided by length of said contig,
# this results in a ratio of amount of reads per contig basepair.
# The median of this value over all contigs in a bin is taken, and this median is
# then multiplied by the estimated genomesize, this is then the amount of reads
# adjusted by the genomesize. These adjusted reads are then divided by the total
# sum of these adjusted reads over the entire sample.
#
# (Median reads per contig basepair * estimated bin contigsize) / total adjusted median read amount with estimated genomesize.


#8: The same method is used for #7, with the only difference being that instead
# of the median of the amount of reads per contig basepair, the average is used.
# The reads are then multiplied by estimated genomesize the same.
#
# (Average reads per contig basepair * estimated bin contigsize) / total adjusted average read amount with estimated genomesize.


#9: The exact same method as #7 is used, but the inverse. So instead of
# multiplication with estimated genomesize, the median reads per basepair is
# divided by the estimated genomesize.
#
# (Median reads per contig basepair / estimated bin contigsize) / total adjusted median read amount with estimated genomesize inversed.


#10: The exact same method as #8 is used, but then we divide by genomesize, not multiply.
#
# (Average reads per contig basepair / estimated bin contigsize) / total adjusted average read amount with estimated genomesize inversed.

#11: The TPM is taken for all contigs in a bin, and the average is taken for each bin.
#The average TPM of a contig is divided by the total.
#
# Average contig TPM in bin / total average TPM

#12: The same method as #11, but the median is used instead.
#
# Median contig TPM in bin / total median TPM

#13: The weighted average TPM from salmon is taken from all contigs in a bin.
# The weights are the lengths of the contigs. This is then divided by the total 
# weighted average.
#
# Weighted average TPM in bin / total weighted average TPM



#for dir in glob.glob("./*/"):
contigdata = {}
bindata = {}
  #id = dir.split("/")[1]

#Reads all the unbinned ids into a list
with open(f"{unbinned_contigs}", "r") as f:
  unbinned_ids = [x.strip(">").strip() for x in f.readlines()]

  
  
#Read the amount of reads mapped to a contig and the contiglength for each contig in the assembly.
with open(f"{readmapping}", "r") as f:
  line = f.readline()
  while line != "":
    line = line.split(" ")
    contigname = line[-1].strip()
    sub = contigname.split("_")
    contiglen = int(sub[3])
    contigcov = float(sub[-1])
    contigdata[contigname] = {'Length': contiglen, 'Mappedreads': int(line[-2]), 'Coverage': contigcov}
    line = f.readline()

  
#This reads the contig read depth for each contig and saves it to the correct contig in the "contigdata" dict.
with open(f"{contig_depthfile}", "r") as f:
  line = f.readline()
  line = f.readline()
  while line != '':
    t = line.split(" ")
    depth = t[1].strip()
    contig = t[0].strip('"')
    contigdata[contig]["Depth"] = float(depth)
    line = f.readline()


#This reads the tpm of each contig from the salmon output and saves it to the correct contig in the "contigdata" dict.
with open(f"{salmon_quant}", "r") as f:
  f.readline()
  line = f.readline()
  while line != '':
    t = line.split("\t")
    contig = t[0]
    tpm = t[3]
    contigdata[contig]["tpm"] = float(tpm)
    line = f.readline()


#Put all the contigs in all bins into a temporary file that shows what bin a contig belongs to.
os.system("rm -f temp.txt")
os.system("""for bin in %s/*.fna; do cat $bin | egrep ">" | awk -v bin="$bin" '{print $1,bin}' >> temp.txt; done""" % bins_dir)
with open("temp.txt", "r") as f:
  line = f.readline()
  while line != "":
    line = line.split()
    contigname = line[0][1:]
    bin = line[-1].split("/")[-1].split(".")[0]
    try:
      bindata[bin].update({contigname: contigdata[contigname]})
    except KeyError:
      bindata[bin] = {contigname: contigdata[contigname]}
    line = f.readline()


#Here, the unbinned contigs get put into a "bin" to quantify this residual
#bin together with the rest.
bindata["unbinned"] = {}
unbinned_size = 0
for contigid in unbinned_ids:
  unbinned_cdat = contigdata[contigid]
  unbinned_size += unbinned_cdat["Length"]
  bindata["unbinned"].update({contigid: unbinned_cdat})


#Reads the estimated genomesize from the genomesizes.tab file generated
# by the calc_genomesize.R script.
genomesizes = {}
with open(f"{genomesizes_file}", "r") as f:
  line = f.readline()
  while line != "":
    t = line.split(" ")
    bin = t[0].split("/")[-1].split(".")[0]
    size = float(t[-1].strip())
    genomesizes[bin] = size
    line = f.readline()
genomesizes["unbinned"] = unbinned_size #This is a "genomesize" generated for the unbinned contigs, by taking their length and summing it up. This way the percentages of the bins don't get inflated by comparison.



#Summing up totals and calculating ratios for the quantification.
bin_quantdata = {}
with open(f"{outputfile}", "w") as o:
  o.write("bin\t")
  o.write("\t".join([str(x) for x in range(1,14)]))
  o.write("\n")
  
  
  
  ########
  #Creating integers for the sum values used in each method.
  ###############################################################
  #The total reads in the sample
  total_reads = 0

  #Contig kmer coverage
  total_coverage = 0 #The total sum of all contig coverages in a sample, for method #2.
  
  #Genomesize adjusted reads
  gs_adjusted_total_med = 0 #This value is the total amount of adjusted reads from method #7. 
  gs_adjusted_total_avg = 0 #This value is total number of adjusted reads from method #8.
  
  #Inversed genomesize adjusted reads.
  gs_i_adjusted_total_med = 0 #This value is the total amount of adjusted reads from method #9.
  gs_i_adjusted_total_avg = 0 #This value is the total amount of adjusted reads from method #10.
  
  #Contig read depth.
  bd_avg_total = 0 #This value is the total sum of all average contigdepth in a sample, for method #3.
  bd_med_total = 0 #This value is the total sum of all median contigdepth in a sample, for method #4.
  
  #Contig read depth adjusted reads.
  bd_adj_total_avg = 0 #This value is the total sum of all average contigdepth adjusted reads in a sample, for method #5.
  bd_adj_total_med = 0 #This value is the total sum of all average contigdepth adjusted reads in a sample, for method #6.
  
  #TPM.
  tpm_avg_total = 0 #The total sum of all average contig TPM of all bins, for method #11.
  tpm_med_total = 0 #The total sum of all median contig TPMs of all bins, for method #12.
  tpm_weight_avg_total = 0 #The total sum of all weighted average TPMs of all bins, for method #13.
  ################################################################
  
  
  #Here, the bindata dict is looped through, which contains a dict for every contig in the bin,
  # with each datapoint saved per contig.
  for bin in bindata.keys():
    
    #########
    #Creating lists for summing up totals per bin and weights
    ###########################################
    #The total amount of reads mapped to the current bin.
    binreads = 0
    #Getting the correct bin values.
    dat = bindata[bin]
    #This is a list which will contain the ratio of mapped reads per basepair for each contig in the bin.
    rpbp_contiglist = []
    #A list that will contain all contigdepths for the entire bin.
    depth_pb = []
    #A list that will contain all contig coverages for the current bin.
    bin_cov_contiglist = []
    #A list to contain all contig lengths in order to be used as weights.
    bin_contig_lengths = []
    #A list to contain all TPM values of all contigs in the bin.
    tpm_contig_list = []
    ###########################################
    
    ###########################################
    #Loop through all contigs in bin to sum and collect values per bin
    ###########################################
    for contig in dat.keys():
      contigdata = dat[contig] #The data of the current contig
      #Add the amount of reads mapping to the contig to the bin total.
      binreads += contigdata["Mappedreads"]
      #Append the contig depth to the bin total list.
      depth_pb.append(contigdata["Depth"]) 
      #Add the coverage to the bin coverage list.
      bin_cov_contiglist.append(contigdata["Coverage"])
      #Add the length to the bin contig lengths list.
      bin_contig_lengths.append(contigdata["Length"])
      #Add the contig TPM to the bin TPM list.
      tpm_contig_list.append(contigdata["tpm"])
    
      #Here the Reads Per contig Base Pair ratio is calculated.
      contig_rpbp = contigdata["Mappedreads"]/contigdata["Length"] #The ratio of number of reads per basepair in the contig, can be seen as the number of reads mapped to the contig adjusted by the contiglength
      rpbp_contiglist.append(contig_rpbp) #The amount reads per contig basepair is put into a list, either the median or the average is used
    ###########################################

    #Calculations for read amount per basepair ratios
    contig_rpbp_avg = numpy.average(rpbp_contiglist) #The average of contig reads per basepair ratios
    contig_rpbp_med = numpy.median(rpbp_contiglist) #The median of contig reads per basepair ratios
      
    #Depth calculations
    contigdepth_avg = numpy.average(depth_pb) #The average contigdepth in the bin.
    bd_avg_total += contigdepth_avg #Sum the total for the 
    contigdepth_med = numpy.median(depth_pb)
    bd_med_total += contigdepth_med
      
    #Depth adjusted reads
    dep_adj_readamt_avg = binreads*contigdepth_avg
    bd_adj_total_avg += dep_adj_readamt_avg
    dep_adj_readamt_med = binreads*contigdepth_med
    bd_adj_total_med += dep_adj_readamt_med
    
    #Coverage calculations
    bin_coverage = numpy.average(bin_cov_contiglist, weights=bin_contig_lengths) #The coverage of a bin calculated as the average of all contig coverages weighted by the contig length
    total_coverage += bin_coverage
    
    #tpm calculations
    tpm_med = numpy.median(tpm_contig_list)
    tpm_med_total += tpm_med
    tpm_avg = numpy.average(tpm_contig_list)
    tpm_avg_total += tpm_avg
    tpm_avg_weighted = numpy.average(tpm_contig_list, weights=bin_contig_lengths)
    tpm_weight_avg_total += tpm_avg_weighted
    
    #Genomesize Adjusted reads
    #Adjusted reads are the amount of mapped reads in the bin adjusted by the genomesize. The two versions are the median and average of the read to basepair ratio in the binned contigs.
    #The adjusted amount of reads based on the genomesize. If the median amount of reads mapped to each basepair in a contig is 2, then the adjusted reads is twice the number of basepairs in the genomesize.
    #Median
    adjusted_reads_med = contig_rpbp_med*genomesizes[bin]
    gs_adjusted_total_med += adjusted_reads_med
    #Average
    adjusted_reads_avg = contig_rpbp_avg*genomesizes[bin]
    gs_adjusted_total_avg += adjusted_reads_avg
    
    #Genomesize adjusted reads inverse.
    #Median
    adjusted_reads_med_i = contig_rpbp_med/genomesizes[bin]
    gs_i_adjusted_total_med += adjusted_reads_med_i
    #Average
    adjusted_reads_avg_i = contig_rpbp_avg/genomesizes[bin]
    gs_i_adjusted_total_avg += adjusted_reads_avg_i

    #Each calculated value is saved into a dict called "bin_quantdata" for dividing with the sample totals later.
    bin_quantdata[bin] = {"bin_reads": binreads, \
    "bin_depth_avg": contigdepth_avg, \
    "bin_depth_med": contigdepth_med, \
    "adj_reads_dep_avg": dep_adj_readamt_avg, \
    "adj_reads_dep_med": dep_adj_readamt_med, \
    "tpm_med": tpm_med, \
    "tpm_avg": tpm_avg, \
    "tpm_weighted": tpm_avg_weighted, \
    "bin_coverage": bin_coverage, \
    "genomesize": genomesizes[bin], \
    "rpbp_ratio_avg": contig_rpbp_avg, \
    "rpbp_ratio_med": contig_rpbp_med, \
    "adjusted_read_amt_med": adjusted_reads_med, \
    "adjusted_read_amt_avg": adjusted_reads_avg, \
    "adjusted_read_amt_med_i": adjusted_reads_med_i, \
    "adjusted_read_amt_avg_i": adjusted_reads_avg_i}
    
    total_reads += binreads

  #Final calculation of full percentages of each bin.
  for bin in bin_quantdata.keys():
    bindata = bin_quantdata[bin]
    
    #Method #1
    bin_readratio = (bindata['bin_reads']/total_reads)*100
    
    #Bin coverage divided by the sum of all bin coverages in the sample.
    #Method #2
    coverage_percentage = (bindata["bin_coverage"]/total_coverage)*100
    
    #The bin_depthratio, which is basically the same but it uses the bin depth, which is basically read coverage.
    #Method #3
    bin_depthratio_avg = (bindata["bin_depth_avg"]/bd_avg_total)*100
    #Method #4
    bin_depthratio_med = (bindata["bin_depth_med"]/bd_med_total)*100
    
    #Adjusted readratios based on depths.
    #Method #5
    depth_adjusted_readratio_avg = (bindata["adj_reads_dep_avg"]/bd_adj_total_avg)*100
    #Method #6
    depth_adjusted_readratio_med = (bindata["adj_reads_dep_med"]/bd_adj_total_med)*100
    
    #Adjusted readratios, which is the percentage caculated with the adjusted read value instead.
    #Method #7
    adjusted_readratio_med = (bindata["adjusted_read_amt_med"]/gs_adjusted_total_med)*100
    #Method #8
    adjusted_readratio_avg = (bindata["adjusted_read_amt_avg"]/gs_adjusted_total_avg)*100
    
    #Adjusted readratios, with inversed genomesize instead.
    #Method #9
    adjusted_readratio_med_i = (bindata["adjusted_read_amt_med_i"]/gs_i_adjusted_total_med)*100
    #Method #10
    adjusted_readratio_avg_i = (bindata["adjusted_read_amt_med_i"]/gs_i_adjusted_total_avg)*100
    
    #Tpm calculations
    #Method #11
    tpm_avg_percentage = (bindata["tpm_avg"]/tpm_avg_total)*100
    #Method #12
    tpm_med_percentage = (bindata["tpm_med"]/tpm_med_total)*100
    #Method #13
    tpm_weighted_percentage = (bindata["tpm_weighted"]/tpm_weight_avg_total)*100
    
    o.write(f"{bin}\t{bin_readratio}\t{coverage_percentage}\t{bin_depthratio_avg}\t{bin_depthratio_med}\t{depth_adjusted_readratio_avg}\t{depth_adjusted_readratio_med}\t{adjusted_readratio_med}\t{adjusted_readratio_avg}\t{adjusted_readratio_med_i}\t{adjusted_readratio_avg_i}\t{tpm_avg_percentage}\t{tpm_med_percentage}\t{tpm_weighted_percentage}\n")


